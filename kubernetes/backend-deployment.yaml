apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
  labels:
    app: backend
spec:
  replicas: 1
  selector:
    matchLabels:
      app: backend
  template:
    metadata:
      labels:
        app: backend
    spec:
      imagePullSecrets:
      - name: ghcr-secret
      containers:
      - name: backend
        image: ghcr.io/aihpi/sketch2image-backend:latest
        resources:
          limits:
            nvidia.com/gpu: 3
        ports:
        - containerPort: 8000
        env:
        - name: NVIDIA_VISIBLE_DEVICES
          value: "0,1,2"
        - name: DEVICE
          value: "cuda"
        - name: HOST
          value: "0.0.0.0"
        - name: PORT
          value: "8000"
        - name: DEBUG_MODE
          value: "false"
        - name: DEFAULT_MODEL_ID
          value: "t2i_adapter_sdxl"
        - name: NUM_INFERENCE_STEPS
          value: "40"
        - name: GUIDANCE_SCALE
          value: "7.5"
        - name: OUTPUT_IMAGE_SIZE
          value: "512"
        - name: HUGGING_FACE_HUB_TOKEN
          valueFrom:
            secretKeyRef:
              name: huggingface-token
              key: token
        
        volumeMounts:
        - name: dataset-storage
          mountPath: /app/dataset
        - name: huggingface-cache
          mountPath: /root/.cache/huggingface
      volumes:
      - name: dataset-storage
        persistentVolumeClaim:
          claimName: backend-dataset-pvc
      - name: huggingface-cache
        persistentVolumeClaim:
          claimName: huggingface-cache-pvc
      nodeSelector:
        nvidia.com/gpu.product: NVIDIA-A30
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
---
apiVersion: v1
kind: Service
metadata:
  name: backend-service
spec:
  selector:
    app: backend
  ports:
    - protocol: TCP
      port: 8000
      targetPort: 8000
  type: ClusterIP
